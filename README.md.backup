# TP4 : Experiment Tracking avec MLflow

**Cours MLOps - D√©tection d'objets avec YOLO tiny**

---

## üìö Objectifs

- ‚úÖ Utiliser MLflow pour tracer plusieurs runs de d√©tection d'objets (YOLO tiny) sur un dataset ultra-l√©ger
- ‚úÖ Comparer les runs dans l'UI MLflow, analyser les m√©triques (mAP, pr√©cision, rappel)
- ‚úÖ Consigner la d√©cision de promotion
- ‚úÖ (Optionnel) Enregistrer le mod√®le choisi dans le Model Registry (Stage : Staging/Production)

---

## üìã Pr√©requis

Avant de commencer, assurez-vous d'avoir install√© :

- **Python 3.11+**
- **Git**
- **Docker Desktop** (pour MLflow et MinIO)
- **PowerShell** (Windows) ou **bash** (Linux/macOS)

---

## üöÄ D√©p√¥t de D√©part

**Forkez le d√©p√¥t** : [MLflow-CV-Yolo](https://github.com/your-fork/MLflow-CV-Yolo)

Puis clonez **VOTRE fork** :

```bash
# Remplacez <URL_DE_VOTRE_FORK> par l'URL de votre fork
git clone <URL_DE_VOTRE_FORK>.git
cd mlflow-cv-yolo
```

---

## üìù Proc√©dure D√©taill√©e

### 0Ô∏è‚É£ Fork & Clone (obligatoire en premier)

Sur GitLab/GitHub :
1. Cliquez sur **Fork** sur le d√©p√¥t MLflow-CV-Yolo
2. Clonez votre fork en local (voir commande ci-dessus)

---

### 1Ô∏è‚É£ Pr√©paration de l'Environnement Python

#### Windows PowerShell :

```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
python -m pip install --upgrade pip
pip install -r requirements.txt
```

#### Linux/macOS :

```bash
python3 -m venv .venv
source .venv/bin/activate
python -m pip install --upgrade pip
pip install -r requirements.txt
```

#### Windows CMD :

```cmd
python -m venv .venv
.\.venv\Scripts\activate.bat
python -m pip install --upgrade pip
pip install -r requirements.txt
```

---

### 2Ô∏è‚É£ G√©n√©ration du Mini-Dataset (COCO128 ‚Üí 1 classe person) & Tracking DVC

#### G√©n√©rer le dataset minimal :

```bash
python tools/make_tiny_person_from_coco128.py
```

**R√©sultat attendu** :
- 60 images au total
- 40 images pour l'entra√Ænement (train)
- 10 images pour la validation (val)
- 10 images pour le test (test)
- 1 seule classe : **person**

#### Tracker le dataset avec DVC :

Le tracking DVC assure la reproductibilit√© des donn√©es.

```bash
# Initialiser DVC (si pas d√©j√† fait dans ce repo)
dvc init

# Ajouter tout le dossier du dataset (images + labels)
dvc add data/tiny_coco -R

# Commit Git des m√©tadonn√©es DVC et de l'ignore
git add data/tiny_coco.dvc .gitignore .dvc/ .gitattributes
git commit -m "Track dataset tiny_coco with DVC"
```

#### (Optionnel) Configurer un remote DVC et pousser les blobs :

**Exemple local** :
```bash
dvc remote add -d localfs ./dvcstore
dvc push
```

**Exemple MinIO** (r√©utiliser le TP DVC si configur√©) :
```bash
dvc remote add -d storage s3://mlops-dvc
dvc remote modify storage endpointurl http://localhost:9000
dvc remote modify storage use_ssl false
dvc remote modify storage region us-east-1
dvc push
```

---

### 3Ô∏è‚É£ D√©marrer MLflow (backend SQLite + artefacts MinIO)

#### Lancer les services Docker :

```bash
docker compose up -d
docker compose ps
docker compose logs -f mlflow  # Ctrl+C pour sortir
```

#### V√©rifier l'acc√®s :

- **UI MLflow** : http://localhost:5000
- **Console MinIO** : http://localhost:9001  
  (identifiants dans `docker-compose.yml` ou `mlflow.env`)

‚úÖ **Checkpoint** : Vous devriez voir l'interface MLflow dans votre navigateur

---

### 4Ô∏è‚É£ Pointer le Script & Callbacks vers le M√™me Serveur MLflow

Configurez la variable d'environnement pour que tous les scripts utilisent le m√™me serveur MLflow.

#### Linux/macOS (bash/zsh) :

```bash
export MLFLOW_TRACKING_URI=http://localhost:5000
```

#### Windows PowerShell :

```powershell
$env:MLFLOW_TRACKING_URI = "http://localhost:5000"
```

#### Windows CMD :

```cmd
set MLFLOW_TRACKING_URI=http://localhost:5000
```

---

### 5Ô∏è‚É£ Lancer un Run Baseline

Depuis la racine du projet :

#### Mode package (recommand√©) :

```bash
python -m src.train_cv --epochs 3 --imgsz 320 --exp-name cv_yolo_tiny
```

#### OU lancement direct :

```bash
python src/train_cv.py --epochs 3 --imgsz 320 --exp-name cv_yolo_tiny
```

**Dur√©e estim√©e** : 1-2 minutes

‚úÖ **Checkpoint** : V√©rifiez dans MLflow UI qu'un nouveau run appara√Æt

---

### 6Ô∏è‚É£ G√©n√©rer une Grille de Runs (8 runs)

La grille de runs permet de tester diff√©rentes combinaisons d'hyperparam√®tres.

#### Linux/macOS :

```bash
chmod +x scripts/run_grid.sh
bash scripts/run_grid.sh
```

#### Windows PowerShell :

```powershell
powershell -ExecutionPolicy Bypass -File scripts\run_grid.ps1
```

#### Windows CMD :

```cmd
scripts\run_grid.cmd
```

**Dur√©e estim√©e** : 5-10 minutes (selon le nombre de configurations)

**Configurations test√©es** :
- Tailles d'image : 320, 416
- Learning rates : 0.005, 0.01
- Seeds : 1, 42
- Epochs : 3 (fixe)

‚úÖ **Checkpoint** : Vous devriez voir 8-9 runs dans MLflow UI

---

### 7Ô∏è‚É£ Comparaison dans l'UI MLflow

#### Acc√©der √† l'exp√©rience :

1. Ouvrir http://localhost:5000
2. Menu **Experiments** ‚Üí `cv_yolo_tiny` (ou **All Experiments**)
3. Filtrer la p√©riode sur **All runs**
4. S√©lectionner plusieurs runs (cochez les cases)
5. Cliquer sur **Compare**

#### Vue d'ensemble des runs :

![Liste des runs MLflow](img/run.png)
*Figure 1 : Vue d'ensemble des runs dans l'interface MLflow*

#### M√©triques √† examiner :

Dans l'√©cran de comparaison, analysez :
- **mAP@50** : Pr√©cision moyenne √† 50% IoU
- **mAP@50-95** : Pr√©cision moyenne sur diff√©rents seuils IoU
- **Precision** : Proportion de vraies d√©tections parmi les d√©tections
- **Recall** : Proportion de d√©tections parmi les objets r√©els

#### Artefacts disponibles :

Pour chaque run, ouvrez les artefacts :
- `results.png` : Courbes d'entra√Ænement
- `confusion_matrix.png` : Matrice de confusion
- `PR_curve.png` : Courbe Pr√©cision-Recall
- `F1_curve.png` : Courbe F1-score
- `weights/best.pt` : Meilleur mod√®le (poids)
- `weights/last.pt` : Dernier checkpoint

#### R√©sultats d'entra√Ænement :

![Courbes d'entra√Ænement](img/results.png)
*Figure 2 : Courbes d'entra√Ænement - Loss, mAP, Precision, Recall par √©poque*

**Observations** :
- Box Loss d√©cro√Æt r√©guli√®rement (convergence normale)
- mAP@50 augmente progressivement
- Precision/Recall doivent √™tre √©quilibr√©s

#### Matrice de confusion :


**Interpr√©tation** :
- **True Positives** : Personnes correctement d√©tect√©es
- **False Positives** : Background d√©tect√© comme personne (√† minimiser)
- **False Negatives** : Personnes manqu√©es (√† minimiser)
- **True Negatives** : Background correctement ignor√©

---

### 8Ô∏è‚É£ Export et Tableau de D√©cision

#### Export des r√©sultats :

Dans l'√©cran de comparaison MLflow :
- Utilisez l'**export CSV** (bouton en haut √† droite)
- OU faites des **captures d'√©cran** des tableaux de m√©triques

#### Compl√©ter le template de d√©cision :

Fichier √† remplir : `reports/templates/decision_template.md`

**Sections √† compl√©ter** :

1. **Objectifs et Contraintes**
   - Objectif principal (ex: maximiser mAP@50-95)
   - Contraintes (dataset limit√©, temps d'entra√Ænement, etc.)

2. **Candidat Promu**
   - Run ID du meilleur mod√®le
   - Param√®tres utilis√©s (epochs, imgsz, lr, seed)
   - M√©triques obtenues (mAP, precision, recall)

3. **Arguments POUR/CONTRE**
   - Comparer 2-3 alternatives
   - Lister avantages et inconv√©nients

4. **Risques et Mitigations**
   - Identifier 4 risques principaux
   - Proposer des strat√©gies d'att√©nuation

5. **D√©cision Finale**
   - **OUI** ‚úÖ ou **NON** ‚ùå
   - Justification claire
   - Conditions √©ventuelles

6. **√âtapes Suivantes**
   - Plan d'action court terme
   - Plan d'action moyen terme
   - Plan d'action long terme

---

## üìä Exemple de Comparaison

| Run | Epochs | ImgSz | LR | Seed | mAP@50-95 | mAP@50 | Precision | Recall |
|-----|--------|-------|-----|------|-----------|--------|-----------|--------|
| **Run 1** | 3 | 416 | 0.01 | 42 | **0.2729** | 0.3228 | 0.008 | 0.7742 |
| Run 2 | 3 | 416 | 0.01 | 1 | 0.2586 | 0.3013 | 0.008 | 0.7742 |
| Run 3 | 3 | 320 | 0.01 | 42 | 0.2314 | 0.2751 | 0.0084 | 0.7097 |
| Run 4 | 3 | 320 | 0.005 | 42 | 0.2250 | 0.2680 | 0.0078 | 0.6935 |

**Insights** :
- üèÜ `imgsz=416` surpasse `imgsz=320` (+19% de mAP@50-95)
- üèÜ `lr=0.01` est optimal (vs 0.005)
- üèÜ `seed=42` l√©g√®rement meilleur que `seed=1` (variance < 6%)

**Configuration gagnante** : epochs=3, imgsz=416, lr=0.01, seed=42
## üìö Ressources

- [Documentation MLflow](https://mlflow.org/docs/latest/)
- [Documentation DVC](https://dvc.org/doc)
- [Guide YOLOv8 Ultralytics](https://docs.ultralytics.com/)
- [Dataset COCO](https://cocodataset.org/)


